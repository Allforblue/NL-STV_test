import streamlit as st
import pandas as pd
import geopandas as gpd
import os
import sys
from pathlib import Path
import logging

# --- ç¯å¢ƒè®¾ç½® ---
# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥ core æ¨¡å—
current_dir = Path(__file__).resolve().parent
sys.path.append(str(current_dir))

# å¼•å…¥æ ¸å¿ƒæ¨¡å—
from core.ingestion.loader_factory import LoaderFactory
from core.llm.ollama_client import LocalLlamaClient
from core.profiler.semantic_analyzer import SemanticAnalyzer
from core.generation.code_generator import CodeGenerator
from core.execution.executor import CodeExecutor
from core.generation.goal_explorer import GoalExplorer  # [æ–°å¢] ç›®æ ‡æ¢ç´¢å™¨

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="NL-STV Platform",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)


# --- ç¼“å­˜èµ„æº (å•ä¾‹æ¨¡å¼) ---
@st.cache_resource
def get_core_modules():
    """åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒç»„ä»¶ï¼Œé¿å…é‡å¤åŠ è½½ LLM"""
    try:
        # ç»Ÿä¸€ä½¿ç”¨åŒä¸€ä¸ª LLM å®¢æˆ·ç«¯
        client = LocalLlamaClient(model_name="llama3.1:latest")

        analyzer = SemanticAnalyzer(client)
        generator = CodeGenerator(client)
        executor = CodeExecutor()
        explorer = GoalExplorer(client)

        return analyzer, generator, executor, explorer
    except Exception as e:
        st.error(f"æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        return None, None, None, None


@st.cache_data
def load_data_for_analysis(file_path, use_full_data=False):
    """
    åŠ è½½ç”¨äºç»˜å›¾çš„æ•°æ®ã€‚
    æ ¹æ®å¼€å…³å†³å®šæ˜¯å…¨é‡åŠ è½½è¿˜æ˜¯é‡‡æ ·åŠ è½½ã€‚
    """
    loader = LoaderFactory.get_loader(file_path)

    # Shapefile/GeoJSON é€šå¸¸ä½“ç§¯å¯æ§ï¼Œæ€»æ˜¯å…¨é‡åŠ è½½ä»¥ä¿è¯åœ°å›¾å®Œæ•´æ€§
    if file_path.endswith('.shp') or file_path.endswith('.geojson'):
        return loader.load(file_path)

    if use_full_data:
        # å…¨é‡æ¨¡å¼ï¼šé€‚åˆç»Ÿè®¡åˆ†æï¼Œä½†å‰ç«¯æ¸²æŸ“æ•£ç‚¹å›¾å¯èƒ½ä¼šå¡
        return loader.load(file_path)
    else:
        # æé€Ÿæ¨¡å¼ï¼šé‡‡æ · 50,000 è¡Œï¼Œé€‚åˆå¿«é€Ÿæ¢ç´¢å’Œæ•£ç‚¹å›¾é¢„è§ˆ
        return loader.peek(file_path, n=50000)


# --- è¾…åŠ©å‡½æ•° ---
def save_uploaded_file(uploaded_file):
    save_dir = "data_sandbox"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    file_path = os.path.join(save_dir, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path


# --- ä¸»é€»è¾‘ ---
def main():
    st.title("ğŸ—ºï¸ NL-STV: AI é©±åŠ¨çš„æ—¶ç©ºæ•°æ®åˆ†æå¹³å°")

    # 1. åˆå§‹åŒ–ç»„ä»¶
    analyzer, generator, executor, explorer = get_core_modules()
    if not analyzer:
        st.stop()

    # 2. åˆå§‹åŒ– Session State
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "analysis_summary" not in st.session_state:
        st.session_state.analysis_summary = None
    if "suggested_goals" not in st.session_state:
        st.session_state.suggested_goals = []
    if "current_file" not in st.session_state:
        st.session_state.current_file = None
    if "last_use_full" not in st.session_state:
        st.session_state.last_use_full = False
    # ç”¨äºå¤„ç†æŒ‰é’®ç‚¹å‡»è§¦å‘èŠå¤©
    if "prompt_trigger" not in st.session_state:
        st.session_state.prompt_trigger = None

    # 3. ä¾§è¾¹æ ï¼šæ§åˆ¶é¢æ¿
    with st.sidebar:
        st.header("ğŸ“‚ æ•°æ®æ¥å…¥")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV/Parquet/Shapefile)",
            type=["csv", "parquet", "zip", "shp"]
        )

        st.markdown("---")
        st.header("âš™ï¸ è®¾ç½®")
        use_full_data = st.toggle(
            "ğŸš€ å¯ç”¨å…¨é‡æ•°æ®æ¨¡å¼",
            value=False,
            help="å¼€å¯ååŠ è½½æ‰€æœ‰æ•°æ®ã€‚ç»Ÿè®¡æ›´å‡†ï¼Œä½†å¤§é‡ç‚¹çš„ç»˜å›¾å¯èƒ½å˜æ…¢ã€‚"
        )

        st.info(f"ğŸ’¡ AI æ¨¡å‹: Llama 3.1 (Local)")

        # é‡ç½®é€»è¾‘ï¼šå¦‚æœæ¢äº†æ–‡ä»¶ OR åˆ‡æ¢äº†æ¨¡å¼ï¼Œæ¸…ç©ºçŠ¶æ€
        file_changed = uploaded_file and uploaded_file.name != st.session_state.current_file
        mode_changed = use_full_data != st.session_state.last_use_full

        if file_changed or mode_changed:
            st.session_state.current_file = uploaded_file.name if uploaded_file else None
            st.session_state.last_use_full = use_full_data
            st.session_state.analysis_summary = None
            st.session_state.suggested_goals = []
            st.session_state.messages = []
            st.cache_data.clear()  # æ¸…é™¤æ—§çš„æ•°æ®ç¼“å­˜

    # 4. æ ¸å¿ƒæµç¨‹
    if uploaded_file:
        file_path = save_uploaded_file(uploaded_file)

        # --- Phase 1: è‡ªåŠ¨åˆ†æä¸ç›®æ ‡ç”Ÿæˆ ---
        if not st.session_state.analysis_summary:
            with st.status("ğŸ” AI æ­£åœ¨é˜…è¯»æ•°æ®...", expanded=True) as status:
                st.write("æ­£åœ¨æå–æ•°æ®æŒ‡çº¹ä¸è¯­ä¹‰...")
                summary = analyzer.analyze(file_path)

                if "error" in summary:
                    status.update(label="âŒ åˆ†æå¤±è´¥", state="error")
                    st.error(summary["error"])
                    st.stop()

                st.session_state.analysis_summary = summary

                st.write("ğŸ’¡ æ­£åœ¨æ„æ€åˆ†ææ–¹å‘ (Goal Exploration)...")
                goals = explorer.generate_goals(summary)
                st.session_state.suggested_goals = goals

                status.update(label="âœ… æ•°æ®æ„ŸçŸ¥å®Œæˆ", state="complete", expanded=False)

        # å±•ç¤ºæ•°æ®æ‘˜è¦
        summary = st.session_state.analysis_summary
        with st.expander("ğŸ“Š æŸ¥çœ‹æ•°æ®æ‘˜è¦ä¸è¯­ä¹‰æ˜ å°„", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**æ•°æ®ç±»å‹**: {summary['semantic_analysis'].get('dataset_type', 'N/A')}")
                st.markdown(f"**æ€»è¡Œæ•°**: {summary['basic_stats']['rows']:,}")
            with col2:
                st.markdown(f"**AI æè¿°**: {summary['semantic_analysis'].get('description', 'N/A')}")

            st.table(
                pd.DataFrame(list(summary['semantic_analysis']['semantic_tags'].items()), columns=['åˆ—å', 'è¯­ä¹‰æ ‡ç­¾']))

        # --- Phase 2: å¯¹è¯å¼ç»˜å›¾ ---
        st.divider()
        st.subheader("ğŸ’¬ AI å¯è§†åŒ–åŠ©æ‰‹")

        # 4.1 æ¨èç›®æ ‡æŒ‰é’® (Goal Explorer)
        if st.session_state.suggested_goals:
            st.caption("âœ¨ çŒœä½ æƒ³é—®ï¼š")
            # åŠ¨æ€åˆ›å»ºåˆ—
            cols = st.columns(len(st.session_state.suggested_goals))
            for i, goal in enumerate(st.session_state.suggested_goals):
                if cols[i].button(goal, key=f"goal_btn_{i}", use_container_width=True):
                    st.session_state.prompt_trigger = goal

        # 4.2 èŠå¤©å†å²å±•ç¤º
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                if msg["type"] == "text":
                    st.markdown(msg["content"])
                elif msg["type"] == "plot":
                    st.plotly_chart(msg["content"], use_container_width=True)
                elif msg["type"] == "code":
                    with st.expander("æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç "):
                        st.code(msg["content"], language="python")

        # 4.3 è¾“å…¥å¤„ç†é€»è¾‘
        # ä¼˜å…ˆå¤„ç†æŒ‰é’®ç‚¹å‡»ï¼Œå¦åˆ™å¤„ç†è¾“å…¥æ¡†
        user_input = None
        chat_input_val = st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š'ç”»å‡ºè½¦è´¹çš„åˆ†å¸ƒ' æˆ– 'å±•ç¤ºODæµå‘'")

        if st.session_state.prompt_trigger:
            user_input = st.session_state.prompt_trigger
            st.session_state.prompt_trigger = None  # æ¶ˆè´¹æ‰è§¦å‘å™¨
        elif chat_input_val:
            user_input = chat_input_val

        # 4.4 æ‰§è¡Œé€»è¾‘
        if user_input:
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "type": "text", "content": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)

            # AI å¤„ç†
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("ğŸ¤” æ­£åœ¨æ€è€ƒç»˜å›¾ä»£ç ...")

                # A. åŠ è½½æ•°æ®ä¸Šä¸‹æ–‡
                try:
                    df_context = load_data_for_analysis(file_path, use_full_data=use_full_data)
                except Exception as e:
                    st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
                    st.stop()

                # B. ä»£ç ç”Ÿæˆä¸æ‰§è¡Œå¾ªç¯ (å«è‡ªæ„ˆæœºåˆ¶)
                try:
                    # åˆæ¬¡ç”Ÿæˆ
                    generated_code = generator.generate_code(user_input, summary)

                    # æ‰§è¡Œ
                    message_placeholder.markdown("âš¡ æ­£åœ¨æ‰§è¡Œä»£ç ...")
                    exec_result = executor.execute(generated_code, df_context)

                    # === è‡ªæ„ˆæœºåˆ¶ (Self-Healing Loop) ===
                    max_retries = 2
                    retry_count = 0

                    while not exec_result.success and retry_count < max_retries:
                        retry_count += 1
                        message_placeholder.warning(f"âš ï¸ ä»£ç æŠ¥é”™ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {retry_count} æ¬¡è‡ªåŠ¨ä¿®å¤...")

                        # è°ƒç”¨ä¿®å¤
                        fixed_code = generator.fix_code(
                            original_code=generated_code,
                            error_trace=exec_result.error,
                            context_summary=summary
                        )

                        # é‡è¯•æ‰§è¡Œ
                        generated_code = fixed_code
                        exec_result = executor.execute(generated_code, df_context)
                    # ===================================

                    # ç»“æœå¤„ç†
                    if exec_result.success:
                        # æˆåŠŸ
                        st.plotly_chart(exec_result.result, use_container_width=True)

                        # æ„å»ºæˆåŠŸæ¶ˆæ¯
                        row_count = len(df_context)
                        success_msg = f"âœ… å›¾è¡¨ç”ŸæˆæˆåŠŸï¼(åŸºäº {row_count:,} æ¡æ•°æ®)"
                        if retry_count > 0:
                            success_msg += f" | âœ¨ è‡ªåŠ¨ä¿®å¤äº† {retry_count} ä¸ªé”™è¯¯ã€‚"

                        message_placeholder.markdown(success_msg)

                        # ä¿å­˜å†å²
                        st.session_state.messages.append(
                            {"role": "assistant", "type": "plot", "content": exec_result.result})
                        st.session_state.messages.append(
                            {"role": "assistant", "type": "code", "content": generated_code})

                        with st.expander("æŸ¥çœ‹æœ€ç»ˆä»£ç "):
                            st.code(generated_code, language="python")
                    else:
                        # å¤±è´¥ (é‡è¯•åä¾ç„¶å¤±è´¥)
                        error_msg = f"âŒ æŠ±æ­‰ï¼Œæˆ‘å°è¯•äº† {retry_count} æ¬¡ä¿®å¤ä½†ä¾ç„¶å¤±è´¥ã€‚\n\n**é”™è¯¯ä¿¡æ¯**: \n```\n{exec_result.error}\n```"
                        message_placeholder.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "type": "text", "content": error_msg})
                        with st.expander("æŸ¥çœ‹æœ€åç”Ÿæˆçš„ä»£ç "):
                            st.code(generated_code, language="python")

                except Exception as e:
                    st.error(f"ç³»ç»Ÿå†…éƒ¨é”™è¯¯: {e}")

    else:
        # Landing Page
        st.markdown("""
        ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ NL-STV æ—¶ç©ºåˆ†æå¹³å°

        è¿™æ˜¯ä¸€ä¸ªåŸºäº LLM çš„æ™ºèƒ½æ•°æ®å¯è§†åŒ–å·¥å…·ã€‚å®ƒèƒ½å¤Ÿç†è§£æ‚¨çš„æ•°æ®è¯­ä¹‰ï¼Œå¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªåŠ¨ç¼–å†™ Python ä»£ç ç»˜å›¾ã€‚

        **åŠŸèƒ½äº®ç‚¹ï¼š**
        - ğŸ§  **è¯­ä¹‰æ„ŸçŸ¥**: è‡ªåŠ¨è¯†åˆ«æ—¶é—´ã€åæ ‡ã€ä¸šåŠ¡æŒ‡æ ‡ã€‚
        - ğŸ—£ï¸ **å¯¹è¯ç»˜å›¾**: è¯´å‡ºæ‚¨çš„éœ€æ±‚ï¼Œè‡ªåŠ¨ç”Ÿæˆ Plotly äº¤äº’å¼å›¾è¡¨ã€‚
        - ğŸ› ï¸ **è‡ªåŠ¨è‡ªæ„ˆ**: ä»£ç æŠ¥é”™ï¼ŸAI ä¼šè‡ªå·± Debug å¹¶é‡è¯•ã€‚
        - ğŸ’¡ **ç›®æ ‡æ¨è**: ä¸çŸ¥é“é—®ä»€ä¹ˆï¼ŸAI ä¼šä¸»åŠ¨ç»™æ‚¨æ¨èåˆ†ææ–¹å‘ã€‚

        **è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹ä½“éªŒ (æ”¯æŒ CSV, Parquet, Shapefile)ã€‚**
        """)


if __name__ == "__main__":
    main()