import streamlit as st
import pandas as pd
import geopandas as gpd
import os
import sys
import re
from pathlib import Path
import logging

# --- ç¯å¢ƒè®¾ç½® ---
# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥ core æ¨¡å—
current_dir = Path(__file__).resolve().parent
sys.path.append(str(current_dir))

from core.ingestion.loader_factory import LoaderFactory
from core.llm.AI_client import AIClient  # ç¡®ä¿ä½¿ç”¨çš„æ˜¯æ”¯æŒ DeepSeek çš„ Client
from core.profiler.semantic_analyzer import SemanticAnalyzer
from core.generation.code_generator import CodeGenerator
from core.execution.executor import CodeExecutor
from core.generation.goal_explorer import GoalExplorer
from core.generation.viz_editor import VizEditor  # [æ–°å¢] å¯¼å…¥ç¼–è¾‘å™¨

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="NL-STV Platform",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)


# --- è¾…åŠ©å·¥å…·ï¼šå˜é‡åæ¸…æ´— ---
def sanitize_var_name(filename):
    """
    å°†æ–‡ä»¶åè½¬æ¢ä¸ºåˆæ³•çš„ Python å˜é‡åã€‚
    ä¾‹å¦‚: 'taxi_zones.shp' -> 'df_taxi_zones'
    """
    # ç§»é™¤æ‰©å±•å
    name = os.path.splitext(filename)[0]
    # æ›¿æ¢éå­—æ¯æ•°å­—ä¸ºä¸‹åˆ’çº¿
    clean_name = re.sub(r'[^a-zA-Z0-9]', '_', name)
    # é¿å…æ•°å­—å¼€å¤´, ä¸”ç»Ÿä¸€åŠ  df_ å‰ç¼€
    if clean_name[0].isdigit():
        clean_name = "df_" + clean_name
    elif not clean_name.startswith("df_"):
        clean_name = "df_" + clean_name
    return clean_name.lower()


# --- ç¼“å­˜èµ„æº ---
@st.cache_resource
def get_core_modules():
    try:
        # è¿™é‡Œä½¿ç”¨ DeepSeek æ¨¡å‹
        client = AIClient(
            model_name="deepseek-chat"
        )
        return (
            SemanticAnalyzer(client),
            CodeGenerator(client),
            CodeExecutor(),
            GoalExplorer(client),
            VizEditor(client)  # [æ–°å¢] è¿”å›ç¼–è¾‘å™¨
        )
    except Exception as e:
        st.error(f"æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        return None, None, None, None, None


@st.cache_data
def load_data_snapshot(file_path, use_full_data=False):
    """åŠ è½½å•ä¸ªæ–‡ä»¶çš„æ•°æ®"""
    loader = LoaderFactory.get_loader(file_path)

    # åœ°ç†æ•°æ®é€šå¸¸å…¨é‡åŠ è½½
    if file_path.endswith('.shp') or file_path.endswith('.geojson'):
        return loader.load(file_path)

    if use_full_data:
        return loader.load(file_path)
    else:
        return loader.peek(file_path, n=50000)


def save_uploaded_files(uploaded_files):
    """ä¿å­˜æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶åˆ° data_sandbox"""
    save_dir = "data_sandbox"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    saved_paths = []
    for up_file in uploaded_files:
        file_path = os.path.join(save_dir, up_file.name)
        with open(file_path, "wb") as f:
            f.write(up_file.getbuffer())
        saved_paths.append(file_path)
    return saved_paths


def get_analyzable_files(file_paths):
    """
    ç­›é€‰å‡ºä¸»æ•°æ®æ–‡ä»¶ï¼ˆæ’é™¤ .dbf, .shx ç­‰ä¼´ç”Ÿæ–‡ä»¶ï¼‰ã€‚
    """
    valid_exts = ['.csv', '.parquet', '.shp', '.geojson', '.xlsx']
    return [f for f in file_paths if os.path.splitext(f)[1].lower() in valid_exts]


# --- æ ¸å¿ƒæŸ¥è¯¢å¤„ç† (ç»Ÿä¸€å…¥å£) ---
def handle_query(query_text, summaries, modules, data_context, force_new=False):
    """
    å¤„ç†æŸ¥è¯¢é€»è¾‘ï¼šåŒºåˆ† ç”Ÿæˆæ–°å›¾(Generate) å’Œ ä¿®æ”¹æ—§å›¾(Edit)
    modules: (generator, executor, editor)
    """
    # è§£åŒ…æ¨¡å—
    generator, executor, editor = modules

    # 1. è®°å½•ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "type": "text", "content": query_text})
    with st.chat_message("user"):
        st.markdown(query_text)

    # 2. AI å¤„ç†
    with st.chat_message("assistant"):
        msg_holder = st.empty()

        try:
            # === é€»è¾‘åˆ†æµ: ç¼–è¾‘ vs ç”Ÿæˆ ===
            # å¦‚æœå­˜åœ¨ä¸Šä¸‹æ–‡ä»£ç ï¼Œä¸”ç”¨æˆ·æ²¡æœ‰å¼ºåˆ¶å¼€å¯â€œæ–°å›¾è¡¨æ¨¡å¼â€ï¼Œåˆ™è¿›å…¥ç¼–è¾‘æ¨¡å¼
            if st.session_state.last_generated_code and not force_new:
                msg_holder.markdown("ğŸ¨ æ­£åœ¨åŸºäºç°æœ‰å›¾è¡¨è¿›è¡Œä¿®æ”¹ (Editing)...")
                code = editor.edit_code(
                    original_code=st.session_state.last_generated_code,
                    query=query_text,
                    summaries=summaries
                )
            else:
                msg_holder.markdown("ğŸ¤” æ­£åœ¨æ„æ€æ–°å›¾è¡¨ (Generating)...")
                code = generator.generate_code(query_text, summaries)

            # === æ‰§è¡Œä»£ç  ===
            msg_holder.markdown("âš¡ æ­£åœ¨æ‰§è¡Œä»£ç ...")
            res = executor.execute(code, data_context)

            # === è‡ªæ„ˆæœºåˆ¶ (Self-Healing) ===
            # è¿™é‡Œå¤ç”¨ generator çš„ fix_codeï¼Œå› ä¸ºå®ƒåŒ…å«æœ€å…¨çš„ GIS è§„åˆ™åº“
            retries = 3
            count = 0
            while not res.success and count < retries:
                count += 1
                msg_holder.warning(f"âš ï¸ ä»£ç æŠ¥é”™ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {count} æ¬¡è‡ªåŠ¨ä¿®å¤...")
                code = generator.fix_code(code, res.error, summaries)
                res = executor.execute(code, data_context)

            # === ç»“æœå±•ç¤º ===
            if res.success:
                # [å…³é”®] æ›´æ–°ä¸Šä¸‹æ–‡ä»£ç 
                st.session_state.last_generated_code = code

                # ä¿å­˜åˆ°å†å²è®°å½•
                st.session_state.messages.append({"role": "assistant", "type": "plot", "content": res.result})
                st.session_state.messages.append({"role": "assistant", "type": "code", "content": code})

                # [æ ¸å¿ƒä¿®å¤] å¼ºåˆ¶é¡µé¢é‡ç»˜ï¼Œç¡®ä¿æŒ‰é’®åŒºèƒ½ç«‹åˆ»æ£€æµ‹åˆ° last_generated_code å¹¶æ˜¾ç¤ºå‡ºæ¥
                st.rerun()

            else:
                err_msg = f"âŒ æ‰§è¡Œå¤±è´¥: \n```\n{res.error}\n```"
                msg_holder.error(err_msg)
                st.session_state.messages.append({"role": "assistant", "type": "text", "content": err_msg})
                with st.expander("æŸ¥çœ‹æœ€åä»£ç "):
                    st.code(code, language="python")

        except Exception as e:
            st.error(f"System Error: {e}")


# --- ä¸»ç¨‹åº ---
def main():
    st.title("ğŸ—ºï¸ NL-STV: äº¤äº’å¼æ—¶ç©ºåˆ†æå¹³å°")

    # 1. åˆå§‹åŒ–æ¨¡å—
    analyzer, generator, executor, explorer, editor = get_core_modules()
    if not analyzer: st.stop()

    # æ‰“åŒ… modules æ–¹ä¾¿ä¼ é€’
    modules_pack = (generator, executor, editor)

    # Session State åˆå§‹åŒ–
    if "messages" not in st.session_state: st.session_state.messages = []
    if "data_summaries" not in st.session_state: st.session_state.data_summaries = []
    if "uploaded_filenames" not in st.session_state: st.session_state.uploaded_filenames = []
    if "suggested_goals" not in st.session_state: st.session_state.suggested_goals = []
    if "prompt_trigger" not in st.session_state: st.session_state.prompt_trigger = None
    if "last_use_full" not in st.session_state: st.session_state.last_use_full = False

    # ä¸Šä¸‹æ–‡çŠ¶æ€
    if "last_generated_code" not in st.session_state: st.session_state.last_generated_code = None
    if "last_query" not in st.session_state: st.session_state.last_query = None

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‚ å¤šæ–‡ä»¶æ¥å…¥")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ‰€æœ‰ç›¸å…³æ–‡ä»¶ (æ”¯æŒ .csv, .parquet, .shp åŠä¼´ç”Ÿæ–‡ä»¶)",
            type=["csv", "parquet", "zip", "shp", "dbf", "shx", "prj", "sbn", "sbx", "xml", "cpg"],
            accept_multiple_files=True
        )

        st.markdown("---")
        st.header("âš™ï¸ è®¾ç½®")
        use_full = st.toggle("ğŸš€ å…¨é‡æ¨¡å¼", value=False)
        st.info(f"ğŸ’¡ AI æ¨¡å‹: DeepSeek-V3")

        # çŠ¶æ€é‡ç½®æ£€æµ‹
        current_names = sorted([f.name for f in uploaded_files]) if uploaded_files else []
        file_changed = current_names != st.session_state.uploaded_filenames
        mode_changed = use_full != st.session_state.last_use_full

        if file_changed or mode_changed:
            st.session_state.uploaded_filenames = current_names
            st.session_state.last_use_full = use_full
            st.session_state.data_summaries = []
            st.session_state.messages = []
            st.session_state.suggested_goals = []
            st.session_state.last_generated_code = None
            st.session_state.last_query = None
            st.cache_data.clear()

    if uploaded_files:
        # 1. ä¿å­˜ä¸ç­›é€‰
        all_paths = save_uploaded_files(uploaded_files)
        analyzable_paths = get_analyzable_files(all_paths)

        if not analyzable_paths:
            st.warning("å·²ä¸Šä¼ æ–‡ä»¶ï¼Œä½†æœªæ£€æµ‹åˆ°æ”¯æŒçš„ä¸»æ•°æ®æ ¼å¼ (.csv, .parquet, .shp)ã€‚")
        else:
            # 2. åˆ†æè¯­ä¹‰
            if not st.session_state.data_summaries:
                summaries = []
                with st.status("ğŸ” æ­£åœ¨è§£æå¤šæºæ•°æ®...", expanded=True) as status:
                    for path in analyzable_paths:
                        fname = os.path.basename(path)
                        st.write(f"æ­£åœ¨åˆ†æ: {fname} ...")

                        summary = analyzer.analyze(path)
                        if "error" not in summary:
                            var_name = sanitize_var_name(fname)
                            summary['variable_name'] = var_name
                            summaries.append(summary)
                            st.write(f"âœ… å·²åŠ è½½ä¸ºå˜é‡: `{var_name}`")
                        else:
                            st.error(f"{fname} åˆ†æå¤±è´¥: {summary['error']}")

                    st.session_state.data_summaries = summaries

                    if summaries:
                        st.write("ğŸ’¡ ç”Ÿæˆåˆ†æå»ºè®®...")
                        st.session_state.suggested_goals = explorer.generate_goals(summaries[0])

                    status.update(label="âœ… æ‰€æœ‰æ–‡ä»¶åŠ è½½å®Œæˆ", state="complete", expanded=False)

            # 3. å‡†å¤‡æ•°æ®ä¸Šä¸‹æ–‡
            data_context = {}
            for summary in st.session_state.data_summaries:
                path = summary['file_info']['path']
                var_name = summary['variable_name']
                try:
                    df = load_data_snapshot(path, use_full_data=use_full)
                    data_context[var_name] = df
                except Exception as e:
                    st.error(f"åŠ è½½å˜é‡ {var_name} å¤±è´¥: {e}")

            # 4. UI å±•ç¤º
            if st.session_state.data_summaries:
                with st.expander("ğŸ“Š å·²åŠ è½½çš„æ•°æ®é›†å˜é‡ (å¯åœ¨å¯¹è¯ä¸­ç›´æ¥ä½¿ç”¨)", expanded=True):
                    for summary in st.session_state.data_summaries:
                        st.markdown(f"**`{summary['variable_name']}`** ({summary['file_info']['name']})")
                        st.caption(f"åŒ…å«åˆ—: {', '.join(list(summary['basic_stats']['column_stats'].keys())[:5])}...")

            # 5. äº¤äº’åŒºåŸŸ
            st.divider()
            st.subheader("ğŸ’¬ AI å¯è§†åŒ–åŠ©æ‰‹")

            # A. æ¨èæŒ‰é’®
            if st.session_state.suggested_goals:
                cols = st.columns(len(st.session_state.suggested_goals))
                for i, goal in enumerate(st.session_state.suggested_goals):
                    if cols[i].button(goal, key=f"btn_{i}"):
                        st.session_state.prompt_trigger = goal

            # B. å†å²è®°å½• (è¿™é‡Œä¼šæ˜¾ç¤ºæˆåŠŸåçš„å›¾è¡¨)
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    if msg["type"] == "text":
                        st.markdown(msg["content"])
                    elif msg["type"] == "plot":
                        st.plotly_chart(msg["content"], use_container_width=True)
                    elif msg["type"] == "code":
                        with st.expander("æŸ¥çœ‹ä»£ç "):
                            st.code(msg["content"], language="python")

            # --- è¾“å…¥ä¸æ§åˆ¶åŒº ---
            col_tools = st.columns([1, 1.5, 5])
            trigger_query = None
            force_new_toggle = False

            # C. é‡æ–°ç”ŸæˆæŒ‰é’®
            if st.session_state.last_query:
                if col_tools[0].button("ğŸ”„ é‡æ–°ç”Ÿæˆ", help="é‡è¯•ä¸Šä¸€æ¬¡æŒ‡ä»¤"):
                    trigger_query = st.session_state.last_query

            # D. æ–°å›¾è¡¨æ¨¡å¼å¼€å…³ (ä»…å½“æœ‰ä¸Šä¸‹æ–‡æ—¶æ˜¾ç¤º)
            if st.session_state.last_generated_code:
                with col_tools[1]:
                    force_new_toggle = st.toggle(
                        "ğŸ†• æ–°å›¾è¡¨æ¨¡å¼",
                        value=False,
                        help="å¼€å¯åå°†å¿½ç•¥å½“å‰å›¾è¡¨ï¼Œæ ¹æ®æŒ‡ä»¤é‡æ–°ç”Ÿæˆæ–°å›¾ã€‚"
                    )

            # E. è¾“å…¥æ¡†
            chat_input_val = st.chat_input("è¾“å…¥æŒ‡ä»¤ (ä¾‹å¦‚ 'æŠŠé¢œè‰²æ”¹æˆçº¢è‰²' æˆ– 'å…³è”è¡¨Aå’Œè¡¨B')")

            # ä¼˜å…ˆçº§åˆ¤æ–­
            if st.session_state.prompt_trigger:
                trigger_query = st.session_state.prompt_trigger
                st.session_state.prompt_trigger = None
                force_new_toggle = True  # ç‚¹å‡»æ¨èé—®é¢˜é€šå¸¸æ„å‘³ç€æƒ³è¦æ–°å›¾
            elif chat_input_val:
                trigger_query = chat_input_val

            # æ‰§è¡Œå¤„ç†
            if trigger_query:
                st.session_state.last_query = trigger_query
                # ä¼ é€’æ‰€æœ‰æ¨¡å—åŒ…
                handle_query(trigger_query, st.session_state.data_summaries, modules_pack, data_context,
                             force_new=force_new_toggle)

    else:
        st.markdown("""
        ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ NL-STV å¤šæºæ•°æ®åˆ†æå¹³å°

        è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶ã€‚

        **ğŸ’¡ æç¤ºï¼š**
        - **å¤šæ–‡ä»¶**: æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼ˆå¦‚ä¸šåŠ¡æ•°æ® + åŒºåŸŸ Shapefileï¼‰ã€‚
        - **Shapefile**: è¯·åŠ¡å¿…ä¸Šä¼  `.shp` åŠå…¶ä¾èµ–æ–‡ä»¶ (`.dbf`, `.shx`)ã€‚
        - **äº¤äº’**: æ”¯æŒåŸºäºå½“å‰å›¾è¡¨è¿›è¡Œå¤šè½®å¯¹è¯ä¿®æ”¹ï¼ˆå¦‚ "æŠŠå›¾ä¾‹å»æ‰"ï¼‰ã€‚
        """)


if __name__ == "__main__":
    main()